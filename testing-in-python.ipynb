{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8a1ceda-3d1a-428f-8b2f-5223bd768079",
   "metadata": {},
   "source": [
    "# Simple Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16761ea-4ed0-4b1c-a08c-da9fc2760c24",
   "metadata": {},
   "source": [
    "**Software testing:**\n",
    "The process of evaluating computer code to determine whether or not it does what you expect it to do"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce57ddff-ecf4-4131-a61e-7e9cf2692f56",
   "metadata": {},
   "source": [
    "# Unit tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f281a1ac-8d00-4bfb-9d47-48c7d8326f38",
   "metadata": {},
   "source": [
    "## unittest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09c7325-41d8-45e1-ad58-e5f7f53e876c",
   "metadata": {},
   "source": [
    "A unittest provides developers with a set of tools to construct and run tests. These tests can be run on individual components or by isolating units of code to ensure their correctness. By running unittests, developers can identify and fix any bugs that appear, creating a more reliable code. In this reading, you will learn about unittest concepts, how to use and when to use them, and view an example along the way.\n",
    "\n",
    "**Concepts**\n",
    "\n",
    "Unittest relies on the following concepts:\n",
    "\n",
    "- **Test fixture:** This refers to preparing to perform one or more tests. In addition, test fixtures also include any actions involved in testing cleanup. This could involve creating temporary or proxy databases, directories, or starting a server process.\n",
    "\n",
    "- **Test case:** This is the individual unit of testing that looks for a specific response to a set of inputs. If needed, TestCase is a base class provided by unittest and can be used to create new test cases.\n",
    "\n",
    "- **Test suite:** This is a collection of test cases, test suites, or a combination of both. It is used to compile tests that should be executed together.\n",
    "\n",
    "- **Test runner:** This runs the test and provides developers with the outcome’s data. The test runner can use different interfaces, like graphical or textual, to provide the developer with the test results. It can also provide a special value to developers to communicate the test results. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8fdb29-ac59-42f2-a79f-2308e9e3538d",
   "metadata": {},
   "source": [
    "**Use case**\n",
    "\n",
    "Let’s look at a test case example where the Python code simulates a cake factory and performs different functions. These include choosing different sizes and flavors of a cake, including small, medium, and large, and chocolate or vanilla. In addition, the simple class allows developers to add sprinkles or cherries to the cake, return a list of ingredients, and return the price of the cake based on size and toppings. Run the following code: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0d42ebb-39d1-4fb4-aa8f-f39bf1fa796e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['flour', 'sugar', 'eggs', 'cocoa', 'sprinkles', 'cherries'], 14)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "\n",
    "class CakeFactory:\n",
    " def __init__(self, cake_type: str, size: str):\n",
    "   self.cake_type = cake_type\n",
    "   self.size = size\n",
    "   self.toppings = []\n",
    "\n",
    "   # Price based on cake type and size\n",
    "   self.price = 10 if self.cake_type == \"chocolate\" else 8\n",
    "   self.price += 2 if self.size == \"medium\" else 4 if self.size == \"large\" else 0\n",
    "\n",
    " def add_topping(self, topping: str):\n",
    "     self.toppings.append(topping)\n",
    "     # Adding 1 to the price for each topping\n",
    "     self.price += 1\n",
    "\n",
    " def check_ingredients(self) -> List[str]:\n",
    "     ingredients = ['flour', 'sugar', 'eggs']\n",
    "     ingredients.append('cocoa') if self.cake_type == \"chocolate\" else ingredients.append('vanilla extract')\n",
    "     ingredients += self.toppings\n",
    "     return ingredients\n",
    "\n",
    " def check_price(self) -> float:\n",
    "     return self.price\n",
    "\n",
    "# Example of creating a cake and adding toppings\n",
    "cake = CakeFactory(\"chocolate\", \"medium\")\n",
    "cake.add_topping(\"sprinkles\")\n",
    "cake.add_topping(\"cherries\")\n",
    "cake_ingredients = cake.check_ingredients()\n",
    "cake_price = cake.check_price()\n",
    "\n",
    "\n",
    "cake_ingredients, cake_price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b539e120-e657-4806-bda6-5f24ab5bac32",
   "metadata": {},
   "source": [
    "In the code above, the cake factory class and methods are defined. Now it’s time to define the unittest methods to test the different functions of the code. The test suite includes tests for the cake’s flavor, size, toppings, ingredients, and price. The first test case in the suite will intentionally provide the wrong value—and that’s what we want! Create specific statements to make sure the program is behaving as it should. That includes providing incorrect data to determine if the program will provide failed results. Because unittest is class-based,  encapsulate these statements into test methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ca3710d-ff87-45be-ac10-6deade6eec05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.018s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=4 errors=0 failures=0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "\n",
    "class TestCakeFactory(unittest.TestCase):\n",
    " def test_create_cake(self):\n",
    "   cake = CakeFactory(\"vanilla\", \"small\")\n",
    "   self.assertEqual(cake.cake_type, \"vanilla\")\n",
    "   self.assertEqual(cake.size, \"small\")\n",
    "   self.assertEqual(cake.price, 8) # Vanilla cake, small size\n",
    "\n",
    " def test_add_topping(self):\n",
    "     cake = CakeFactory(\"chocolate\", \"large\")\n",
    "     cake.add_topping(\"sprinkles\")\n",
    "     self.assertIn(\"sprinkles\", cake.toppings)\n",
    "\n",
    " def test_check_ingredients(self):\n",
    "     cake = CakeFactory(\"chocolate\", \"medium\")\n",
    "     cake.add_topping(\"cherries\")\n",
    "     ingredients = cake.check_ingredients()\n",
    "     self.assertIn(\"cocoa\", ingredients)\n",
    "     self.assertIn(\"cherries\", ingredients)\n",
    "     self.assertNotIn(\"vanilla extract\", ingredients)\n",
    "\n",
    " def test_check_price(self):\n",
    "     cake = CakeFactory(\"vanilla\", \"large\")\n",
    "     cake.add_topping(\"sprinkles\")\n",
    "     cake.add_topping(\"cherries\")\n",
    "     price = cake.check_price()\n",
    "     self.assertEqual(price, 14) # Vanilla cake, large size + 2 toppings\n",
    "\n",
    "\n",
    "# Running the unittests\n",
    "unittest.TextTestRunner().run(unittest.TestLoader().loadTestsFromTestCase(TestCakeFactory))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc5ed89-7cc4-4f5d-91ed-e9124a193dff",
   "metadata": {},
   "source": [
    "The program calls the `TextTestRunner()` method, which returns a runner (`TextTestResult`). It says one failure occurred: the statement `self.assertEqual(price, 13)` was incorrect, as it should have been 14. How can we correct that part of the test? Update that part of the code to the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e1639f4-db0c-42e5-a237-c617a01ed583",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.005s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=1 errors=0 failures=0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "\n",
    "\n",
    "# Fixing the test_check_price method\n",
    "class TestCakeFactory(unittest.TestCase):\n",
    " # ... Other tests remain the same\n",
    "\n",
    " def test_check_price(self):\n",
    "     cake = CakeFactory(\"vanilla\", \"large\")\n",
    "     cake.add_topping(\"sprinkles\")\n",
    "     cake.add_topping(\"cherries\")\n",
    "     price = cake.check_price()\n",
    "     self.assertEqual(price, 14) # Vanilla cake, large size + 2 toppings\n",
    "\n",
    "# Re-running the unittests\n",
    "unittest.TextTestRunner().run(unittest.TestLoader().loadTestsFromTestCase(TestCakeFactory))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e3cafc-0904-4883-9530-3c208623eaa5",
   "metadata": {},
   "source": [
    "**Key takeaways**\n",
    "\n",
    "Unittest can assist developers in building a strong and effective code for their programs. The tools allow developers to test small, isolated functionality units to catch bugs and glitches that could potentially cause larger problems if run with the overall code program. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9cd663-2a28-4405-b0e5-4b21f8c0877e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51b8d69c-ce86-4bc8-ad23-f004aadc055c",
   "metadata": {},
   "source": [
    "## pytest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2084b11-418c-4aff-b7e0-47bc4ff53526",
   "metadata": {},
   "source": [
    "Pytest is a powerful Python testing tool that assists programmers in writing more effective and stable programs. It helps to simplify the process of writing, organizing and executing tests. It can be used to write a variety of tests including: integration, end-to-end, and functional tests. It supports automatic test discovery and generates informative test reports. \n",
    "\n",
    "In this reading, you will learn more about pytests, how to write tests with pytest, and its fixtures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098772e0-b2f0-4eae-b1a7-f7440ea4856e",
   "metadata": {},
   "source": [
    "**How to write tests**\n",
    "\n",
    "Pytests are written with functions that use the operation, assert(). An assert is a commonly used debugging tool in Python that allows programmers to include sanity checks in their code. They ensure certain conditions or assumptions hold true during runtime. If the condition provided to assert() turns out to be false, it indicates a bug in the code, an exception is raised, and halts the program’s execution. Typically, code provides an assert condition followed by an optional message. An example is: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab9cf249-4643-4d59-a550-efc9d6f99af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide(a, b):\n",
    "\tassert b != 0, \"Cannot divide by zero\"\n",
    "\treturn a / b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a24f816-ff9d-4036-974a-f6dba2532c4b",
   "metadata": {},
   "source": [
    "An AssertionError message is raised informing the programmer that it is not possible to divide a value by zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a669b49-78e9-4377-8057-216df724efcf",
   "metadata": {},
   "source": [
    "**Pytest fixtures**\n",
    "\n",
    "Fixtures are used to separate parts of code that only run for tests. They are reusable pieces of test setups and teardown code that are shared across multiple tests. Fixtures benefit developers by assisting in keeping their tests clean and avoiding code duplication. Let’s look at an example of using a pytest in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00b044a3-34de-4d80-906f-66b91a2c2d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "class Fruit:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.cubed = False\n",
    "\n",
    "\n",
    "    def cube(self):\n",
    "        self.cubed = True\n",
    "\n",
    "\n",
    "class FruitSalad:\n",
    "    def __init__(self, *fruit_bowl):\n",
    "        self.fruit = fruit_bowl\n",
    "        self._cube_fruit()\n",
    "\n",
    "\n",
    "    def _cube_fruit(self):\n",
    "        for fruit in self.fruit:\n",
    "            fruit.cube()\n",
    "\n",
    "\n",
    "# Arrange\n",
    "@pytest.fixture\n",
    "def fruit_bowl():\n",
    "    return [Fruit(\"apple\"), Fruit(\"banana\")]\n",
    "\n",
    "\n",
    "def test_fruit_salad(fruit_bowl):\n",
    "    # Act\n",
    "    fruit_salad = FruitSalad(*fruit_bowl)\n",
    "\n",
    "\n",
    "    # Assert\n",
    "    assert all(fruit.cubed for fruit in fruit_salad.fruit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1738c3-558a-48fd-9e0c-3bd9f0cb968d",
   "metadata": {},
   "source": [
    "In this example, `test_fruit_salad`  requests `fruit_bowl`. When pytest recognizes this, it executes the fruit_bowl fixture function and takes the object it returns into `test_fruit_salad` as the `fruit_bowl` argument. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be7b81c-199e-4446-ad37-9fe4c91d4113",
   "metadata": {},
   "source": [
    "**Key takeaways**\n",
    "\n",
    "Pytest is a user-friendly testing framework for developers writing code in Python to focus on creating simple and clear tests. Pytests are written using the assert() operation to compare actual values with expected results. Fixtures provide developers a way to share common test data and environment configurations while ensuring consistent testing conditions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbc1321-3de5-4089-b8de-c50cbb960fef",
   "metadata": {},
   "source": [
    "## Comparing unittest and pytest\n",
    "\n",
    "Both unittest and pytest provide developers with tools to create robust and reliable code through different forms of tests. Both can be used while creating programs within Python, and it is the developer’s preference on which type they want to use.\n",
    "\n",
    "In this reading, you will learn about the differences between unittest and pytest, and when to use them.\n",
    "\n",
    "**Key differences**\n",
    "\n",
    "- `Unittest` is a tool that is built directly into Python, while `pytest` must be imported from outside your script. Test discovery acts differently for each test type. \n",
    "\n",
    "- `Unittest` has the functionality to automatically detect test cases within an application, but it must be called from the command line. `Pytests` are performed automatically using the prefix test_. \n",
    "\n",
    "- `Unittests` use an object-oriented approach to write tests, while `pytest`s use a functional approach. Pytests use built-in assert statements, making tests easier to read and write. On the other hand, unittests provide special assert methods like `assertEqual()` or `assertTrue()`.\n",
    "\n",
    "Backward compatibility exists between `unittest` and `pytest`. Because `unittest` is built directly into Python, these test suites are more easily executed. But that doesn’t mean that `pytest` cannot be executed. Because of backward compatibility, the `unittest` framework can be seamlessly executed using the `pytest` framework without major modifications. This allows developers to adopt `pytest` gradually and integrate them into their code.\n",
    "\n",
    "**Key takeaways**\n",
    "\n",
    "`Unittest` and `pytest` are both beneficial to developers in executing tests on their code written in Python. Each one has its pros and cons, and it is up to the developer and their preference on which type of testing framework they want to use. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829b2052-2ab0-4669-87ce-2fa163040b64",
   "metadata": {},
   "source": [
    "## Review: Unit tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146aaf70-6249-4fbb-8650-b66749c37cc2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fed7d6d4-228c-4e6b-8381-ec64ab0bb5a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ada Lovelace'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import re\n",
    "def rearrange_name(name):\n",
    "    result = re.search(r\"^([\\w .]*), ([\\w .]*)$\", name)\n",
    "    return \"{} {}\".format(result[2], result[1])\n",
    "    \n",
    "# from rearrange import rearrange_name\n",
    "\n",
    "rearrange_name(\"Lovelace, Ada\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f417d04-ad8d-4ae6-833b-5be8acf7c856",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24c57ced-5f5b-4cfd-90de-6c2357dd604f",
   "metadata": {},
   "source": [
    "## Review: Writing unit tests in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b2bf1f3-e843-4e51-9365-a9f15c854f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.003s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import re\n",
    "\n",
    "def rearrange_name(name):\n",
    "  result = re.search(r\"^([\\w .]*), ([\\w .]*)$\", name)\n",
    "  return \"{} {}\".format(result[2], result[1])\n",
    "\n",
    "\n",
    "import unittest\n",
    "\n",
    "class TestRearrange(unittest.TestCase):\n",
    "    \n",
    "  def test_basic(self):\n",
    "    testcase = \"Lovelace, Ada\"\n",
    "    expected = \"Ada Lovelace\"\n",
    "    self.assertEqual(rearrange_name(testcase), expected)\n",
    "# Run the tests\n",
    "# if __name__ == '__main__':\n",
    "    # unittest.main()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # unittest.main(exit=False)\n",
    "    # unittest.main(argv=['first-arg-is-ignored'], exit=False)\n",
    "    unittest.TextTestRunner().run(unittest.TestLoader().loadTestsFromTestCase(TestRearrange))\n",
    "\n",
    "# chmod +x rearrange_test.py \n",
    "# ./rearrange_test.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cfac38-7451-47d9-8c59-4361adfd2a98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65efb374-c52c-4592-aebb-ad9248e7b841",
   "metadata": {},
   "source": [
    "## Review: Edge cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db83bc05-06f6-4228-b5d2-6a4c5f7e33e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_empty(self):\n",
    "  testcase = \"\"\n",
    "  expected = \"\"\n",
    "  self.assertEqual(rearrange_name(testcase), expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460d25a6-8b42-4924-9864-814808da57b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e48f754e-a9d3-4217-b1ea-49b473cfacdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def rearrange_name(name):\n",
    "  result = re.search(r\"^([\\w .-]*), ([\\w .-]*)$\", name)\n",
    "  if result is None:\n",
    "    return \"\"\n",
    "  return \"{} {}\".format(result[2], result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2928deb0-15df-4315-8495-29b3c91b2b06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3716259-e4bb-4f33-9d51-6c51ab54d45a",
   "metadata": {},
   "source": [
    "## Review: Additional test cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bd4a427-a698-47ef-8846-012e3e8e8e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def rearrange_name(name):\n",
    "  result = re.search(r\"^([\\w .]*), ([\\w .]*)$\", name)\n",
    "  if result is None:\n",
    "    return name\n",
    "  return \"{} {}\".format(result[2], result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb6dc0eb-f8b4-4358-a3cc-01a40dffc9ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.009s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=4 errors=0 failures=0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import unittest\n",
    "\n",
    "class TestRearrange(unittest.TestCase):\n",
    "  \n",
    "  def test_basic(self):\n",
    "    testcase = \"Lovelace, Ada\"\n",
    "    expected = \"Ada Lovelace\"\n",
    "    self.assertEqual(rearrange_name(testcase), expected)\n",
    "\n",
    "  def test_empty(self):\n",
    "    testcase = \"\"\n",
    "    expected = \"\"\n",
    "    self.assertEqual(rearrange_name(testcase), expected)\n",
    "\n",
    "  def test_double_name(self):\n",
    "    testcase = \"Hopper, Grace M.\"\n",
    "    expected = \"Grace M. Hopper\"\n",
    "    self.assertEqual(rearrange_name(testcase), expected)\n",
    "\n",
    "  def test_one_name(self):\n",
    "    testcase = \"Voltaire\"\n",
    "    expected = \"Voltaire\"\n",
    "    self.assertEqual(rearrange_name(testcase), expected)\n",
    "\n",
    "# Run the tests\n",
    "# unittest.main()\n",
    "unittest.TextTestRunner().run(unittest.TestLoader().loadTestsFromTestCase(TestRearrange))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1669e8c3-b5fc-44e5-9703-a25cc1f2a9c1",
   "metadata": {},
   "source": [
    "# Other Test Concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c24bd3-5ef2-4ece-bf45-fe6a978e337e",
   "metadata": {},
   "source": [
    "- [Monitoring Distributed Systems](https://sre.google/sre-book/monitoring-distributed-systems/)\n",
    "- [Testing for Reliability](https://sre.google/sre-book/testing-reliability/)\n",
    "- [Performance Testing](https://testing.googleblog.com/2007/10/performance-testing.html)\n",
    "- [What is Smoke Testing](https://www.guru99.com/smoke-testing.html)\n",
    "- [What is Exploratory Testing?](https://www.guru99.com/exploratory-testing.html)\n",
    "- [Test first is fun!](https://testing.googleblog.com/2008/09/test-first-is-fun_08.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668fd835-3d8c-4c43-acff-d18cb188f0d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc25f735-20df-48ba-b85d-b55a2c0c264c",
   "metadata": {},
   "source": [
    "# Errors and Exceptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d209f9-9d8d-4e20-9c30-34d9bdd825ff",
   "metadata": {},
   "source": [
    "## The Try-Except concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adbd2c8a-38a9-4d7e-96bb-255dfbe7fe3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "def character_frequency(filename):\n",
    "  \"\"\"Counts the frequency of each character in the given file.\"\"\"\n",
    "  # First try to open the file\n",
    "  try:\n",
    "    f = open(filename)\n",
    "  except OSError:\n",
    "    return None\n",
    "\n",
    "  # Now process the file\n",
    "  characters = {}\n",
    "  for line in f:\n",
    "    for char in line:\n",
    "      characters[char] = characters.get(char, 0) + 1\n",
    "  f.close() \n",
    "  return characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5e7240-b518-4bfa-8d77-2c3d6570b99f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b5fa0dc1-03cc-4787-8f72-ebf316337316",
   "metadata": {},
   "source": [
    "## Raising errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d04720d2-019d-4840-a345-02b279621b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "def validate_user(username, minlen):\n",
    "  if minlen < 1:\n",
    "    raise ValueError(\"minlen must be at least 1\")\n",
    "\n",
    "  if len(username) < minlen:\n",
    "    return False\n",
    "  if not username.isalnum():\n",
    "    return False\n",
    "  return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfa19e8d-236c-4397-8171-c87a4b6affce",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "minlen must be at least 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mvalidate_user\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[13], line 5\u001b[0m, in \u001b[0;36mvalidate_user\u001b[1;34m(username, minlen)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate_user\u001b[39m(username, minlen):\n\u001b[0;32m      4\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m minlen \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m----> 5\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminlen must be at least 1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(username) \u001b[38;5;241m<\u001b[39m minlen:\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: minlen must be at least 1"
     ]
    }
   ],
   "source": [
    "validate_user(\"\", -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a98f1d5-cc56-4087-9ec1-717003f65c28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_user(\"\", 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95321400-4391-4592-8a6e-a2d70868f575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_user(\"myuser\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46b865fb-b980-4587-999b-fcccdd0f33b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'int' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mvalidate_user\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m88\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[13], line 7\u001b[0m, in \u001b[0;36mvalidate_user\u001b[1;34m(username, minlen)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m minlen \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m      5\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminlen must be at least 1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43musername\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m<\u001b[39m minlen:\n\u001b[0;32m      8\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m username\u001b[38;5;241m.\u001b[39misalnum():\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'int' has no len()"
     ]
    }
   ],
   "source": [
    "validate_user(88, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c47909a6-e5eb-4115-a791-81a4644071fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_user([], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c41d5d28-664d-4def-aa2b-af30d103b103",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'isalnum'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mvalidate_user\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mname\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[13], line 9\u001b[0m, in \u001b[0;36mvalidate_user\u001b[1;34m(username, minlen)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(username) \u001b[38;5;241m<\u001b[39m minlen:\n\u001b[0;32m      8\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43musername\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misalnum\u001b[49m():\n\u001b[0;32m     10\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'isalnum'"
     ]
    }
   ],
   "source": [
    "validate_user([\"name\"], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5adb948c-a618-4a0e-a8b7-c11659bb1cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "def validate_user(username, minlen):\n",
    "  assert type(username) == str, \"username must be a string\"\n",
    "  if minlen < 1:\n",
    "    raise ValueError(\"minlen must be at least 1\")\n",
    "\n",
    "  if len(username) < minlen:\n",
    "    return False\n",
    "  if not username.isalnum():\n",
    "    return False\n",
    "  return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5056eb00-9040-47c4-818a-fcae43237bf1",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "username must be a string",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mvalidate_user\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[21], line 4\u001b[0m, in \u001b[0;36mvalidate_user\u001b[1;34m(username, minlen)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate_user\u001b[39m(username, minlen):\n\u001b[1;32m----> 4\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(username) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musername must be a string\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      5\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m minlen \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminlen must be at least 1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAssertionError\u001b[0m: username must be a string"
     ]
    }
   ],
   "source": [
    "validate_user([3], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9277c474-fa94-463a-957a-6b331e047205",
   "metadata": {},
   "source": [
    "## Testing for expected errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7d9ce5ec-e196-4fca-84f7-09bc4b018054",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.007s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=4 errors=0 failures=0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import unittest\n",
    "\n",
    "# from validations import validate_user\n",
    "\n",
    "class TestValidateUser(unittest.TestCase):\n",
    "  def test_valid(self):\n",
    "    self.assertEqual(validate_user(\"validuser\", 3), True)\n",
    "\n",
    "  def test_too_short(self):\n",
    "    self.assertEqual(validate_user(\"inv\", 5), False)\n",
    "\n",
    "  def test_invalid_characters(self):\n",
    "    self.assertEqual(validate_user(\"invalid_user\", 1), False)\n",
    "  def test_invalid_minlen(self):\n",
    "    self.assertRaises(ValueError, validate_user, \"user\", -1)\n",
    "\n",
    "\n",
    "# Run the tests\n",
    "# unittest.main()\n",
    "unittest.TextTestRunner().run(unittest.TestLoader().loadTestsFromTestCase(TestValidateUser))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e53f3d-b6d9-4378-bb61-04388649b717",
   "metadata": {},
   "source": [
    "## Study guide: Handling errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e76de9b-e334-44e1-8a3b-df45b1d8b81d",
   "metadata": {},
   "source": [
    "\n",
    "You’ve learned that in some cases, it’s better to raise an error yourself, and how to test that the right error is raised when that's what you expect. You’ve also learned how to test your code to verify that it does what it should. In this reading, you’ll learn about error handling syntax, including raising exceptions, using an assert statement, and the `try` and `except` clauses. \n",
    "\n",
    "**Exception handling**\n",
    "\n",
    "When performing exception handling, it is important to predict which exceptions can happen. Sometimes, to figure out which exceptions you need to account for, you have to let your program fail.\n",
    "\n",
    "The simplest way to handle exceptions in Python is by using the try and except clauses. \n",
    "\n",
    "In the try clause, Python executes all statements until it encounters an exception. You use the except clause to catch and handle the exception(s) that Python encounters in the try clause.\n",
    "\n",
    "Here is the process for how it works: \n",
    "\n",
    "- Python runs the try clause, e.g., the statement(s) between the `try` and `except` keywords.\n",
    "\n",
    "- If no error occurs, Python skips the except clause and the execution of the try statement is finished.\n",
    "\n",
    "- If an error occurs during execution of the `try` clause, Python skips the rest of the try clause and transfers control to the corresponding except block. If the type of error matches what is listed after the except keyword, Python executes the except clause. The execution then continues on after the `try`/`except` block.\n",
    "\n",
    "- If an exception occurs but it does not match what is listed in the except clause, it is passed onto try statements outside of that try/except block. However, if a handler for that exception cannot be found, the exception becomes an unhandled exception, the execution stops, and Python displays a designated error message. \n",
    "\n",
    "Sometimes, a `try` statement can have more than one `except` clause so that the code can specify handlers for different exceptions. This can help to reduce the number of unhandled exceptions. \n",
    "\n",
    "You can use exceptions to catch almost everything. It is good practice as a developer or programmer to be as specific as possible with the types of exceptions that you intend to handle, especially if you’re creating your own exceptions.  \n",
    "\n",
    "**Raise exceptions**\n",
    "\n",
    "As a developer or programmer, you might want to raise an error yourself. Usually, this happens when some of the conditions necessary for a function to do its job properly aren't met and returning none or some other base value isn't good enough. You can raise an error or raise an exception (also known as “throwing an exception”), which forces a particular exception to occur, and notifies you that something in your code is going wrong or an error has occurred. \n",
    "\n",
    "Here are some instances where raising an exception is a useful tool:\n",
    "\n",
    "- A file doesn’t exist\n",
    "\n",
    "- A network or database connection fails\n",
    "\n",
    "- Your code receives invalid input\n",
    "\n",
    "In the example below, the code raises two built-in Python exceptions:  `raise ValueError` and `raise ZeroDivisionError`. You can find more information on these raises in the example below, along with explanations of potential errors that may occur during an exception.\n",
    "\n",
    "**Example exception handling**\n",
    "\n",
    "Now that you have an understanding of `try` and `except` clauses, `assert` statements, and raising exceptions, consider the following code examples which use all of these concepts together.\n",
    "\n",
    "The basic structure of exception handling is as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ede653a-a95d-4ce9-991a-c386ded91899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File reading function with exception handling\n",
    "def read_file(filename):\n",
    "\ttry:\n",
    "\t\twith open(filename, 'r') as f:\n",
    "\t\t\treturn f.read()\n",
    "\texcept FileNotFoundError:\n",
    "\t\treturn \"File not found!\"\n",
    "\tfinally:\n",
    "\t\tprint(\"Finished reading file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02355657-7a22-4411-a15c-a84d72a15875",
   "metadata": {},
   "source": [
    "Imagine you have a function that reads data from a file and then divides two numbers provided within that file. There are some faults in it that you can catch with exceptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d686343-4b33-4535-bf50-264bcbaf65d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def faulty_read_and_divide(filename):\n",
    "\twith open(filename, 'r') as file:\n",
    "\t\tdata = file.readlines()\n",
    "\t\tnum1 = int(data[0])\n",
    "\t\tnum2 = int(data[1])\n",
    "\t\treturn num1 / num2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8fdd7d-0e15-49c2-ba50-1c59a72a2401",
   "metadata": {},
   "source": [
    "There are several potential issues here:\n",
    "\n",
    "- The file might not exist, causing a `FileNotFoundError`.\n",
    "- The file might not have enough lines of data, leading to an `IndexError`.\n",
    "- The data in the file might not be convertible to integers, raising a `ValueError`.\n",
    "- The second number might be zero, which would raise a `ZeroDivisionError`.\n",
    "\n",
    "To address these potential issues, you can add the appropriate exception handling illustrated below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0c59678c-b276-4136-bd42-d487795138ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhanced_read_and_divide(filename):\n",
    "    try:\n",
    "        with open(filename, 'r') as file:\n",
    "            data = file.readlines()\n",
    "        # Ensure there are at least two lines in the file\n",
    "    \n",
    "        if len(data) < 2:\n",
    "            raise ValueError(\"Not enough data in the file.\")\n",
    "        num1 = int(data[0])\n",
    "        num2 = int(data[1])\n",
    "        # Check if second number is zero\n",
    "        if num2 == 0:\n",
    "            raise ZeroDivisionError(\"The denominator is zero.\")\n",
    "            \n",
    "        return num1 / num2\n",
    "\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        return \"Error: The file was not found.\"\n",
    "    except ValueError as ve:\n",
    "        return f\"Value error: {ve}\"\n",
    "    except ZeroDivisionError as zde:\n",
    "        return f\"Division error: {zde}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5941fab3-fcc1-41a9-a262-361f31a17d80",
   "metadata": {},
   "source": [
    "Now, the function `enhanced_read_and_divide` is equipped to handle potential exceptions gracefully, providing informative error messages to the caller. This way, the code will explain when it fails since you have identified potential fault zones such as when dealing with unpredictable inputs or file content.\n",
    "\n",
    "Notice how the exceptions are instantiated as objects (such as `ValueError` ve) that you can use to further diagnose the issue by printing them out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79284c2c-28d9-4caa-8823-3f35d11b4890",
   "metadata": {},
   "source": [
    "The errors should read:\n",
    "\n",
    "- `File-level issues:`\n",
    "- `Value error: Not enough data in the file.`\n",
    "- `Error: The file was not found.`\n",
    "- `Data-level issues:`\n",
    "- `Value error: invalid literal for int() with base 10: 'apple'`\n",
    "- `Division error: The denominator is zero.`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef6e7b5-2cdc-41be-9c2d-ceb680e30a78",
   "metadata": {},
   "source": [
    "**`assert` statements**\n",
    "\n",
    "`assert` statements help you to verify if a certain condition is met and throw an exception if it isn’t. As is stated in the name, their purpose is to \"assert\" that certain conditions are true at specific points in your program. \n",
    "\n",
    "The `assert` statement exists in almost every programming language and has two main uses:\n",
    "\n",
    "To help detect problems earlier in development, rather than later when some other operation fails. Problems that aren’t addressed until later in the development process can turn out to be more time-intensive and costly to fix.\n",
    "\n",
    "To provide a form of documentation for other developers reading the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40db4afd-44fe-49cb-a259-6d1351857ab5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b4c7379-88df-4c23-92ff-8fc83bc923c2",
   "metadata": {},
   "source": [
    "Automatic testing: A process where software checks itself for errors and confirms that it works correctly\n",
    "\n",
    "Black-box tests: A test where there is an awareness of what the program is supposed to do but not how it does it\n",
    "\n",
    "Edge cases: Inputs to code that produce unexpected results, found at the extreme ends of the ranges of input\n",
    "\n",
    "Pytest: A powerful Python testing tool that assists programmers in writing more effective and stable programs\n",
    "\n",
    "Software testing: A process of evaluating computer code to determine whether or not it does what is expected\n",
    "\n",
    "Test case: This is the individual unit of testing that looks for a specific response to a set of inputs\n",
    "\n",
    "Test fixture: This prepared to perform one or more tests\n",
    "\n",
    "Test suite: This is used to compile tests that should be executed together\n",
    "\n",
    "Test runner: This runs the test and provides developers with the outcome’s data\n",
    "\n",
    "unittest: A set of Python tools to construct and run unit tests\n",
    "\n",
    "Unit tests: A test to verify that small isolated parts of a program work correctly\n",
    "\n",
    "White-box test: A test where test creator knows how the code works and can write test cases that use the understanding to make sure it performs as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6c1b16-6957-46f3-b203-c217c48c2772",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23ec1e6b-cbf4-4ba3-841f-467d0a50622a",
   "metadata": {},
   "source": [
    "# Implement Unit Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "04cec0ea-56a1-4976-8fc4-9a9af83f8abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "breee@abc.edu\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# emails.py\n",
    "\n",
    "import sys\n",
    "import csv\n",
    "\n",
    "def populate_dictionary(filename): \n",
    "  \"\"\"Populate a dictionary with name/email pairs for easy lookup.\"\"\"\n",
    "  email_dict = {}\n",
    "  with open(filename) as csvfile:\n",
    "    lines = csv.reader(csvfile, delimiter = ',')\n",
    "    for row in lines:\n",
    "      name = str(row[0].lower())\n",
    "      email_dict[name] = row[1]\n",
    "  return email_dict\n",
    "\n",
    "def find_email(argv):\n",
    "  \"\"\" Return an email address based on the username given.\"\"\"\n",
    "  # Create the username based on the command line input.\n",
    "  fullname = str(argv[1] + \" \" + argv[2])\n",
    "  # Preprocess the data\n",
    "  email_dict = populate_dictionary('user_emails.csv')\n",
    "  # Find and print the email\n",
    "  return email_dict.get(fullname.lower())\n",
    "\n",
    "def main():\n",
    "  print(find_email([None, \"Bree\", \"Campbell\"]))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2015f073-a9b8-4d47-ab0e-a14e3a1076a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.002s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#!/usr/bin/env python3\n",
    "\n",
    "import unittest\n",
    "# from emails import find_email\n",
    "class EmailsTest(unittest.TestCase):\n",
    "  def test_basic(self):\n",
    "\n",
    "    testcase = [None, \"Bree\", \"Campbell\"]\n",
    "\n",
    "    expected = \"breee@abc.edu\"\n",
    "\n",
    "    self.assertEqual(find_email(testcase), expected)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "  # unittest.main()BaseException\n",
    "  unittest.TextTestRunner().run(unittest.TestLoader().loadTestsFromTestCase(EmailsTest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "17c8f936-2b4c-4ad7-b2c7-b5f89c296072",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.003s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import unittest\n",
    "# from emails import find_email\n",
    "\n",
    "class TestFile(unittest.TestCase):\n",
    "  def test_basic(self):\n",
    "    testcase = [None, \"Bree\", \"Campbell\"]\n",
    "    expected = \"breee@abc.edu\"\n",
    "    self.assertEqual(find_email(testcase), expected)\n",
    "\n",
    "  def test_one_name(self):\n",
    "    testcase = [None, \"John\"]\n",
    "    expected = \"Missing parameters\"\n",
    "    self.assertEqual(find_email(testcase), expected)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  # unittest.main()\n",
    "  unittest.TextTestRunner().run(unittest.TestLoader().loadTestsFromTestCase(EmailsTest))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a25b75e-3ad7-4188-9ea7-d8cac824386d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f1e7675e-e6ca-409a-bc8f-77b24f823e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "breee@abc.edu\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "\n",
    "import sys\n",
    "import csv\n",
    "\n",
    "def populate_dictionary(filename):\n",
    "  \"\"\"Populate a dictionary with name/email pairs for easy lookup.\"\"\"\n",
    "  email_dict = {}\n",
    "  with open(filename) as csvfile:\n",
    "    lines = csv.reader(csvfile, delimiter = ',')\n",
    "    for row in lines:\n",
    "      name = str(row[0].lower())\n",
    "      email_dict[name] = row[1]\n",
    "  return email_dict\n",
    "\n",
    "def find_email(argv):\n",
    "  \"\"\" Return an email address based on the username given.\"\"\"\n",
    "  # Create the username based on the command line input.\n",
    "  try:\n",
    "    fullname = str(argv[1] + \" \" + argv[2])\n",
    "    # Preprocess the data\n",
    "    email_dict = populate_dictionary('user_emails.csv')\n",
    "    # Find and print the email\n",
    "    return email_dict.get(fullname.lower())\n",
    "  except IndexError:\n",
    "    return \"Missing parameters\"\n",
    "\n",
    "def main():\n",
    "  print(find_email([None, \"Bree\", \"Campbell\"]))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bf68c480-70a4-4e53-a6f5-a4ce4a380fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..F\n",
      "======================================================================\n",
      "FAIL: test_two_name (__main__.EmailsTest.test_two_name)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_15328\\1504779233.py\", line 21, in test_two_name\n",
      "    self.assertEqual(find_email(testcase), expected)\n",
      "AssertionError: None != 'No email address found'\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.007s\n",
      "\n",
      "FAILED (failures=1)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "\n",
    "import unittest\n",
    "# from emails import find_email\n",
    "\n",
    "class EmailsTest(unittest.TestCase):\n",
    "  def test_basic(self):\n",
    "    testcase = [None, \"Bree\", \"Campbell\"]\n",
    "    expected = \"breee@abc.edu\"\n",
    "    self.assertEqual(find_email(testcase), expected)\n",
    "\n",
    "  def test_one_name(self):\n",
    "    testcase = [None, \"John\"]\n",
    "    expected = \"Missing parameters\"\n",
    "    self.assertEqual(find_email(testcase), expected)\n",
    "\n",
    "  def test_two_name(self):\n",
    "    testcase = [None, \"Roy\", \"Cooper\"]\n",
    "    expected = \"No email address found\"\n",
    "    self.assertEqual(find_email(testcase), expected)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  # unittest.main()\n",
    "  unittest.TextTestRunner().run(unittest.TestLoader().loadTestsFromTestCase(EmailsTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ebec28-37d9-46ba-96f9-8dcd68af5b81",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "87aa2b27-3ca4-4d18-bbc5-1fd914afcdf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "breee@abc.edu\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import csv\n",
    "import sys\n",
    "\n",
    "def populate_dictionary(filename):\n",
    "  \"\"\"Populate a dictionary with name/email pairs for easy lookup.\"\"\"\n",
    "  email_dict = {}\n",
    "  with open(filename) as csvfile:\n",
    "    lines = csv.reader(csvfile, delimiter = ',')\n",
    "    for row in lines:\n",
    "      name = str(row[0].lower())\n",
    "      email_dict[name] = row[1]\n",
    "  return email_dict\n",
    "\n",
    "def find_email(argv):\n",
    "  \"\"\" Return an email address based on the username given.\"\"\"\n",
    "  # Create the username based on the command line input.\n",
    "  try:\n",
    "    fullname = str(argv[1] + \" \" + argv[2])\n",
    "    # Preprocess the data\n",
    "    email_dict = populate_dictionary('user_emails.csv')\n",
    "     # If email exists, print it\n",
    "    if email_dict.get(fullname.lower()):\n",
    "      return email_dict.get(fullname.lower())\n",
    "    else:\n",
    "      return \"No email address found\"\n",
    "  except IndexError:\n",
    "    return \"Missing parameters\"\n",
    "\n",
    "def main():\n",
    "  print(find_email([None, \"Bree\", \"Campbell\"]))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff82536-97f2-4f14-8c32-4b194beae330",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
