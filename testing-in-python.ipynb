{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8a1ceda-3d1a-428f-8b2f-5223bd768079",
   "metadata": {},
   "source": [
    "# Simple Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16761ea-4ed0-4b1c-a08c-da9fc2760c24",
   "metadata": {},
   "source": [
    "**Software testing:**\n",
    "The process of evaluating computer code to determine whether or not it does what you expect it to do"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce57ddff-ecf4-4131-a61e-7e9cf2692f56",
   "metadata": {},
   "source": [
    "# Unit tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f281a1ac-8d00-4bfb-9d47-48c7d8326f38",
   "metadata": {},
   "source": [
    "## unittest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09c7325-41d8-45e1-ad58-e5f7f53e876c",
   "metadata": {},
   "source": [
    "A unittest provides developers with a set of tools to construct and run tests. These tests can be run on individual components or by isolating units of code to ensure their correctness. By running unittests, developers can identify and fix any bugs that appear, creating a more reliable code. In this reading, you will learn about unittest concepts, how to use and when to use them, and view an example along the way.\n",
    "\n",
    "**Concepts**\n",
    "\n",
    "Unittest relies on the following concepts:\n",
    "\n",
    "- **Test fixture:** This refers to preparing to perform one or more tests. In addition, test fixtures also include any actions involved in testing cleanup. This could involve creating temporary or proxy databases, directories, or starting a server process.\n",
    "\n",
    "- **Test case:** This is the individual unit of testing that looks for a specific response to a set of inputs. If needed, TestCase is a base class provided by unittest and can be used to create new test cases.\n",
    "\n",
    "- **Test suite:** This is a collection of test cases, test suites, or a combination of both. It is used to compile tests that should be executed together.\n",
    "\n",
    "- **Test runner:** This runs the test and provides developers with the outcome’s data. The test runner can use different interfaces, like graphical or textual, to provide the developer with the test results. It can also provide a special value to developers to communicate the test results. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8fdb29-ac59-42f2-a79f-2308e9e3538d",
   "metadata": {},
   "source": [
    "**Use case**\n",
    "\n",
    "Let’s look at a test case example where the Python code simulates a cake factory and performs different functions. These include choosing different sizes and flavors of a cake, including small, medium, and large, and chocolate or vanilla. In addition, the simple class allows developers to add sprinkles or cherries to the cake, return a list of ingredients, and return the price of the cake based on size and toppings. Run the following code: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0d42ebb-39d1-4fb4-aa8f-f39bf1fa796e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['flour', 'sugar', 'eggs', 'cocoa', 'sprinkles', 'cherries'], 14)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "\n",
    "class CakeFactory:\n",
    " def __init__(self, cake_type: str, size: str):\n",
    "   self.cake_type = cake_type\n",
    "   self.size = size\n",
    "   self.toppings = []\n",
    "\n",
    "   # Price based on cake type and size\n",
    "   self.price = 10 if self.cake_type == \"chocolate\" else 8\n",
    "   self.price += 2 if self.size == \"medium\" else 4 if self.size == \"large\" else 0\n",
    "\n",
    " def add_topping(self, topping: str):\n",
    "     self.toppings.append(topping)\n",
    "     # Adding 1 to the price for each topping\n",
    "     self.price += 1\n",
    "\n",
    " def check_ingredients(self) -> List[str]:\n",
    "     ingredients = ['flour', 'sugar', 'eggs']\n",
    "     ingredients.append('cocoa') if self.cake_type == \"chocolate\" else ingredients.append('vanilla extract')\n",
    "     ingredients += self.toppings\n",
    "     return ingredients\n",
    "\n",
    " def check_price(self) -> float:\n",
    "     return self.price\n",
    "\n",
    "# Example of creating a cake and adding toppings\n",
    "cake = CakeFactory(\"chocolate\", \"medium\")\n",
    "cake.add_topping(\"sprinkles\")\n",
    "cake.add_topping(\"cherries\")\n",
    "cake_ingredients = cake.check_ingredients()\n",
    "cake_price = cake.check_price()\n",
    "\n",
    "\n",
    "cake_ingredients, cake_price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b539e120-e657-4806-bda6-5f24ab5bac32",
   "metadata": {},
   "source": [
    "In the code above, the cake factory class and methods are defined. Now it’s time to define the unittest methods to test the different functions of the code. The test suite includes tests for the cake’s flavor, size, toppings, ingredients, and price. The first test case in the suite will intentionally provide the wrong value—and that’s what we want! Create specific statements to make sure the program is behaving as it should. That includes providing incorrect data to determine if the program will provide failed results. Because unittest is class-based,  encapsulate these statements into test methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ca3710d-ff87-45be-ac10-6deade6eec05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.006s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=4 errors=0 failures=0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "\n",
    "class TestCakeFactory(unittest.TestCase):\n",
    " def test_create_cake(self):\n",
    "   cake = CakeFactory(\"vanilla\", \"small\")\n",
    "   self.assertEqual(cake.cake_type, \"vanilla\")\n",
    "   self.assertEqual(cake.size, \"small\")\n",
    "   self.assertEqual(cake.price, 8) # Vanilla cake, small size\n",
    "\n",
    " def test_add_topping(self):\n",
    "     cake = CakeFactory(\"chocolate\", \"large\")\n",
    "     cake.add_topping(\"sprinkles\")\n",
    "     self.assertIn(\"sprinkles\", cake.toppings)\n",
    "\n",
    " def test_check_ingredients(self):\n",
    "     cake = CakeFactory(\"chocolate\", \"medium\")\n",
    "     cake.add_topping(\"cherries\")\n",
    "     ingredients = cake.check_ingredients()\n",
    "     self.assertIn(\"cocoa\", ingredients)\n",
    "     self.assertIn(\"cherries\", ingredients)\n",
    "     self.assertNotIn(\"vanilla extract\", ingredients)\n",
    "\n",
    " def test_check_price(self):\n",
    "     cake = CakeFactory(\"vanilla\", \"large\")\n",
    "     cake.add_topping(\"sprinkles\")\n",
    "     cake.add_topping(\"cherries\")\n",
    "     price = cake.check_price()\n",
    "     self.assertEqual(price, 14) # Vanilla cake, large size + 2 toppings\n",
    "\n",
    "\n",
    "# Running the unittests\n",
    "unittest.TextTestRunner().run(unittest.TestLoader().loadTestsFromTestCase(TestCakeFactory))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc5ed89-7cc4-4f5d-91ed-e9124a193dff",
   "metadata": {},
   "source": [
    "The program calls the `TextTestRunner()` method, which returns a runner (`TextTestResult`). It says one failure occurred: the statement `self.assertEqual(price, 13)` was incorrect, as it should have been 14. How can we correct that part of the test? Update that part of the code to the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e1639f4-db0c-42e5-a237-c617a01ed583",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.001s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=1 errors=0 failures=0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "\n",
    "\n",
    "# Fixing the test_check_price method\n",
    "class TestCakeFactory(unittest.TestCase):\n",
    " # ... Other tests remain the same\n",
    "\n",
    " def test_check_price(self):\n",
    "     cake = CakeFactory(\"vanilla\", \"large\")\n",
    "     cake.add_topping(\"sprinkles\")\n",
    "     cake.add_topping(\"cherries\")\n",
    "     price = cake.check_price()\n",
    "     self.assertEqual(price, 14) # Vanilla cake, large size + 2 toppings\n",
    "\n",
    "# Re-running the unittests\n",
    "unittest.TextTestRunner().run(unittest.TestLoader().loadTestsFromTestCase(TestCakeFactory))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e3cafc-0904-4883-9530-3c208623eaa5",
   "metadata": {},
   "source": [
    "**Key takeaways**\n",
    "\n",
    "Unittest can assist developers in building a strong and effective code for their programs. The tools allow developers to test small, isolated functionality units to catch bugs and glitches that could potentially cause larger problems if run with the overall code program. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9cd663-2a28-4405-b0e5-4b21f8c0877e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51b8d69c-ce86-4bc8-ad23-f004aadc055c",
   "metadata": {},
   "source": [
    "## pytest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2084b11-418c-4aff-b7e0-47bc4ff53526",
   "metadata": {},
   "source": [
    "Pytest is a powerful Python testing tool that assists programmers in writing more effective and stable programs. It helps to simplify the process of writing, organizing and executing tests. It can be used to write a variety of tests including: integration, end-to-end, and functional tests. It supports automatic test discovery and generates informative test reports. \n",
    "\n",
    "In this reading, you will learn more about pytests, how to write tests with pytest, and its fixtures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098772e0-b2f0-4eae-b1a7-f7440ea4856e",
   "metadata": {},
   "source": [
    "**How to write tests**\n",
    "\n",
    "Pytests are written with functions that use the operation, assert(). An assert is a commonly used debugging tool in Python that allows programmers to include sanity checks in their code. They ensure certain conditions or assumptions hold true during runtime. If the condition provided to assert() turns out to be false, it indicates a bug in the code, an exception is raised, and halts the program’s execution. Typically, code provides an assert condition followed by an optional message. An example is: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ab9cf249-4643-4d59-a550-efc9d6f99af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide(a, b):\n",
    "\tassert b != 0, \"Cannot divide by zero\"\n",
    "\treturn a / b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a24f816-ff9d-4036-974a-f6dba2532c4b",
   "metadata": {},
   "source": [
    "An AssertionError message is raised informing the programmer that it is not possible to divide a value by zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a669b49-78e9-4377-8057-216df724efcf",
   "metadata": {},
   "source": [
    "**Pytest fixtures**\n",
    "\n",
    "Fixtures are used to separate parts of code that only run for tests. They are reusable pieces of test setups and teardown code that are shared across multiple tests. Fixtures benefit developers by assisting in keeping their tests clean and avoiding code duplication. Let’s look at an example of using a pytest in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00b044a3-34de-4d80-906f-66b91a2c2d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "class Fruit:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.cubed = False\n",
    "\n",
    "\n",
    "    def cube(self):\n",
    "        self.cubed = True\n",
    "\n",
    "\n",
    "class FruitSalad:\n",
    "    def __init__(self, *fruit_bowl):\n",
    "        self.fruit = fruit_bowl\n",
    "        self._cube_fruit()\n",
    "\n",
    "\n",
    "    def _cube_fruit(self):\n",
    "        for fruit in self.fruit:\n",
    "            fruit.cube()\n",
    "\n",
    "\n",
    "# Arrange\n",
    "@pytest.fixture\n",
    "def fruit_bowl():\n",
    "    return [Fruit(\"apple\"), Fruit(\"banana\")]\n",
    "\n",
    "\n",
    "def test_fruit_salad(fruit_bowl):\n",
    "    # Act\n",
    "    fruit_salad = FruitSalad(*fruit_bowl)\n",
    "\n",
    "\n",
    "    # Assert\n",
    "    assert all(fruit.cubed for fruit in fruit_salad.fruit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1738c3-558a-48fd-9e0c-3bd9f0cb968d",
   "metadata": {},
   "source": [
    "In this example, `test_fruit_salad`  requests `fruit_bowl`. When pytest recognizes this, it executes the fruit_bowl fixture function and takes the object it returns into `test_fruit_salad` as the `fruit_bowl` argument. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be7b81c-199e-4446-ad37-9fe4c91d4113",
   "metadata": {},
   "source": [
    "**Key takeaways**\n",
    "\n",
    "Pytest is a user-friendly testing framework for developers writing code in Python to focus on creating simple and clear tests. Pytests are written using the assert() operation to compare actual values with expected results. Fixtures provide developers a way to share common test data and environment configurations while ensuring consistent testing conditions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbc1321-3de5-4089-b8de-c50cbb960fef",
   "metadata": {},
   "source": [
    "## Comparing unittest and pytest\n",
    "\n",
    "Both unittest and pytest provide developers with tools to create robust and reliable code through different forms of tests. Both can be used while creating programs within Python, and it is the developer’s preference on which type they want to use.\n",
    "\n",
    "In this reading, you will learn about the differences between unittest and pytest, and when to use them.\n",
    "\n",
    "**Key differences**\n",
    "\n",
    "- `Unittest` is a tool that is built directly into Python, while `pytest` must be imported from outside your script. Test discovery acts differently for each test type. \n",
    "\n",
    "- `Unittest` has the functionality to automatically detect test cases within an application, but it must be called from the command line. `Pytests` are performed automatically using the prefix test_. \n",
    "\n",
    "- `Unittests` use an object-oriented approach to write tests, while `pytest`s use a functional approach. Pytests use built-in assert statements, making tests easier to read and write. On the other hand, unittests provide special assert methods like `assertEqual()` or `assertTrue()`.\n",
    "\n",
    "Backward compatibility exists between `unittest` and `pytest`. Because `unittest` is built directly into Python, these test suites are more easily executed. But that doesn’t mean that `pytest` cannot be executed. Because of backward compatibility, the `unittest` framework can be seamlessly executed using the `pytest` framework without major modifications. This allows developers to adopt `pytest` gradually and integrate them into their code.\n",
    "\n",
    "**Key takeaways**\n",
    "\n",
    "`Unittest` and `pytest` are both beneficial to developers in executing tests on their code written in Python. Each one has its pros and cons, and it is up to the developer and their preference on which type of testing framework they want to use. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829b2052-2ab0-4669-87ce-2fa163040b64",
   "metadata": {},
   "source": [
    "## Review: Unit tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146aaf70-6249-4fbb-8650-b66749c37cc2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fed7d6d4-228c-4e6b-8381-ec64ab0bb5a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ada Lovelace'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import re\n",
    "def rearrange_name(name):\n",
    "    result = re.search(r\"^([\\w .]*), ([\\w .]*)$\", name)\n",
    "    return \"{} {}\".format(result[2], result[1])\n",
    "    \n",
    "# from rearrange import rearrange_name\n",
    "\n",
    "rearrange_name(\"Lovelace, Ada\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f417d04-ad8d-4ae6-833b-5be8acf7c856",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24c57ced-5f5b-4cfd-90de-6c2357dd604f",
   "metadata": {},
   "source": [
    "## Review: Writing unit tests in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b2bf1f3-e843-4e51-9365-a9f15c854f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.002s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import re\n",
    "\n",
    "def rearrange_name(name):\n",
    "  result = re.search(r\"^([\\w .]*), ([\\w .]*)$\", name)\n",
    "  return \"{} {}\".format(result[2], result[1])\n",
    "\n",
    "\n",
    "import unittest\n",
    "\n",
    "class TestRearrange(unittest.TestCase):\n",
    "    \n",
    "  def test_basic(self):\n",
    "    testcase = \"Lovelace, Ada\"\n",
    "    expected = \"Ada Lovelace\"\n",
    "    self.assertEqual(rearrange_name(testcase), expected)\n",
    "# Run the tests\n",
    "# if __name__ == '__main__':\n",
    "    # unittest.main()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # unittest.main(exit=False)\n",
    "    # unittest.main(argv=['first-arg-is-ignored'], exit=False)\n",
    "    unittest.TextTestRunner().run(unittest.TestLoader().loadTestsFromTestCase(TestRearrange))\n",
    "\n",
    "# chmod +x rearrange_test.py \n",
    "# ./rearrange_test.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cfac38-7451-47d9-8c59-4361adfd2a98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65efb374-c52c-4592-aebb-ad9248e7b841",
   "metadata": {},
   "source": [
    "## Review: Edge cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db83bc05-06f6-4228-b5d2-6a4c5f7e33e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_empty(self):\n",
    "  testcase = \"\"\n",
    "  expected = \"\"\n",
    "  self.assertEqual(rearrange_name(testcase), expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460d25a6-8b42-4924-9864-814808da57b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e48f754e-a9d3-4217-b1ea-49b473cfacdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def rearrange_name(name):\n",
    "  result = re.search(r\"^([\\w .-]*), ([\\w .-]*)$\", name)\n",
    "  if result is None:\n",
    "    return \"\"\n",
    "  return \"{} {}\".format(result[2], result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2928deb0-15df-4315-8495-29b3c91b2b06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3716259-e4bb-4f33-9d51-6c51ab54d45a",
   "metadata": {},
   "source": [
    "## Review: Additional test cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0bd4a427-a698-47ef-8846-012e3e8e8e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def rearrange_name(name):\n",
    "  result = re.search(r\"^([\\w .]*), ([\\w .]*)$\", name)\n",
    "  if result is None:\n",
    "    return name\n",
    "  return \"{} {}\".format(result[2], result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb6dc0eb-f8b4-4358-a3cc-01a40dffc9ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...F\n",
      "======================================================================\n",
      "FAIL: test_one_name (__main__.TestRearrange.test_one_name)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_9816\\513839392.py\", line 23, in test_one_name\n",
      "    self.assertEqual(rearrange_name(testcase), expected)\n",
      "AssertionError: '' != 'Voltaire'\n",
      "+ Voltaire\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.005s\n",
      "\n",
      "FAILED (failures=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=4 errors=0 failures=1>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import unittest\n",
    "\n",
    "class TestRearrange(unittest.TestCase):\n",
    "  \n",
    "  def test_basic(self):\n",
    "    testcase = \"Lovelace, Ada\"\n",
    "    expected = \"Ada Lovelace\"\n",
    "    self.assertEqual(rearrange_name(testcase), expected)\n",
    "\n",
    "  def test_empty(self):\n",
    "    testcase = \"\"\n",
    "    expected = \"\"\n",
    "    self.assertEqual(rearrange_name(testcase), expected)\n",
    "\n",
    "  def test_double_name(self):\n",
    "    testcase = \"Hopper, Grace M.\"\n",
    "    expected = \"Grace M. Hopper\"\n",
    "    self.assertEqual(rearrange_name(testcase), expected)\n",
    "\n",
    "  def test_one_name(self):\n",
    "    testcase = \"Voltaire\"\n",
    "    expected = \"Voltaire\"\n",
    "    self.assertEqual(rearrange_name(testcase), expected)\n",
    "\n",
    "# Run the tests\n",
    "# unittest.main()\n",
    "unittest.TextTestRunner().run(unittest.TestLoader().loadTestsFromTestCase(TestRearrange))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33334944-5110-4d7d-a451-dd500e7d5bd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435b9b5f-5f82-485d-bad8-cad38b8a9149",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668fd835-3d8c-4c43-acff-d18cb188f0d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efec755-6cb8-44d0-b35a-a0fa61089320",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
